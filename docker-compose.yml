services:
  # copilot-gpt4-service:
  #   image: aaamoon/copilot-gpt4-service:latest
  #   container_name: copilot-gpt4-service
  #   restart: always
  #   ports:
  #     - "10100:8080"
  #   environment:
  #     - COPILOT_TOKEN=${GITHUB_COPILOT_PLUGIN_KEY}
  #     - SUPER_TOKEN=${LOBE_CHAT_ACCESS_CODE}
  #     - ENABLE_SUPER_TOKEN=true
  #     - RATE_LIMIT=200

  network-service:
    image: alpine
    container_name: lobe-network
    ports:
      - ${MINIO_PORT:-9000}:${MINIO_PORT:-9000} # MinIO API
      - 9001:9001 # MinIO Console
      - ${LOGTO_PORT:-3001}:${LOGTO_PORT:-3001} # Logto
      - 3002:3002 # Logto Admin
      - ${LOBE_PORT:-3210}:3210 # LobeChat
    command: tail -f /dev/null
    networks:
      - lobe-network

  postgresql:
    image: pgvector/pgvector:pg16
    container_name: lobe-postgres
    ports:
      - "5432:5432"
    volumes:
      - "./data:/var/lib/postgresql/data"
    environment:
      - POSTGRES_DB=${LOBE_DB_NAME:-lobechat}
      - POSTGRES_PASSWORD=${LOBE_POSTGRES_PASSWORD}
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 5s
      timeout: 5s
      retries: 5
    restart: always
    networks:
      - lobe-network

  minio:
    image: minio/minio
    container_name: lobe-minio
    network_mode: "service:network-service"
    volumes:
      - "./s3_data:/etc/minio/data"
    environment:
      - MINIO_ROOT_USER=${LOBE_MINIO_ROOT_USER}
      - MINIO_ROOT_PASSWORD=${LOBE_MINIO_ROOT_PASSWORD}
      - MINIO_API_CORS_ALLOW_ORIGIN=http://localhost:${LOBE_PORT:-3210}
    restart: always
    command: >
      server /etc/minio/data --address ":${MINIO_PORT:-9000}" --console-address ":9001"

  logto:
    image: svhd/logto
    container_name: lobe-logto
    network_mode: "service:network-service"
    depends_on:
      postgresql:
        condition: service_healthy
    environment:
      - TRUST_PROXY_HEADER=1
      - PORT=${LOGTO_PORT:-3001}
      - DB_URL=postgresql://postgres:${LOBE_POSTGRES_PASSWORD}@postgresql:5432/logto
      - ENDPOINT=http://localhost:${LOGTO_PORT:-3001}
      - ADMIN_ENDPOINT=http://localhost:3002
    entrypoint: ["sh", "-c", "npm run cli db seed -- --swe && npm start"]

  lobe-chat:
    # depends_on:
    #   - copilot-gpt4-service
    # image: lobehub/lobe-chat
    image: lobehub/lobe-chat-database
    container_name: lobe-chat-database
    restart: always
    network_mode: 'service:network-service'
    depends_on:
      postgresql:
        condition: service_healthy
      network-service:
        condition: service_started
      minio:
        condition: service_started
      logto:
        condition: service_started

    environment:
      - APP_URL=http://localhost:3210
      - NEXT_AUTH_SSO_PROVIDERS=logto
      - KEY_VAULTS_SECRET=${LOBE_KEY_VAULTS_SECRET} # 用于加密用户存储的 apikey 等敏感信息。
      - NEXT_AUTH_SECRET=${LOBE_NEXT_AUTH_SECRET} # 用于加密 Auth.js 会话令牌的密钥。
      - NEXTAUTH_URL=http://localhost:${LOBE_PORT:-3210}/api/auth
      - AUTH_LOGTO_ISSUER=http://localhost:${LOGTO_PORT:-3001}/oidc

      - LOGTO_CLIENT_ID=${LOGTO_CLIENT_ID}
      - LOGTO_CLIENT_SECRET=${LOGTO_CLIENT_SECRET}

      # S3: MinIO
      - DATABASE_URL=postgresql://postgres:${LOBE_POSTGRES_PASSWORD}@postgresql:5432/${LOBE_DB_NAME:-lobechat}
      - S3_ACCESS_KEY_ID=${LOBE_S3_ACCESS_KEY_ID}
      - S3_SECRET_ACCESS_KEY=${LOBE_S3_SECRET_ACCESS_KEY}
      - S3_ENDPOINT=http://localhost:${MINIO_PORT:-9000}
      - S3_BUCKET=${MINIO_LOBE_BUCKET:-lobe}
      - S3_PUBLIC_DOMAIN=http://localhost:${MINIO_PORT:-9000}
      - S3_ENABLE_PATH_STYLE=1

      # If you don't choose hack
      # - HTTPS_PROXY=${LOBE_CLIENT_HTTP_PROXY}
      - OPENAI_API_KEY=${LOBE_CHAT_OPENAI_TOKEN}
      - OPENAI_PROXY_URL=${LOBE_CHAT_OPENAI_PROXY_URL}

      # hack github copilot to gpt4
      # - OPENAI_MODEL_LIST=-all,+gpt-3.5-turbo,+gpt-4
      # - OPENAI_API_KEY=${LOBE_CHAT_ACCESS_CODE}
      # - OPENAI_PROXY_URL=http://copilot-gpt4-service:8080/v1
      # - ACCESS_CODE=${LOBE_CHAT_ACCESS_CODE:-lobe66}

      # openai
      - DEFAULT_AGENT_CONFIG=provider=ollama;model=qwen2:7b;enableHistoryCount=true;historyCount=5;params.max_tokens=8000;fetchOnClient=true;

      # - SYSTEM_AGENT=provider=ollama;model=qwen2:7b;
      - SYSTEM_AGENT=topic=ollama/qwen2:7b,agentMeta=ollama/qwen2:7b,queryRewrite=ollama/qwen2:7b,translation=ollama/qwen2:7b

      # google gemini
      - GOOGLE_API_KEY=${GOOGLE_GEMINI_API_KEY}
      # ollama
      - OLLAMA_PROXY_URL=http://host.docker.internal:11434
      - OLLAMA_MODEL_LIST=-all,+qwen2:7b
      # 智谱AI
      - ZHIPU_API_KEY=${OFFICIAL_ZHIPU_TOKEN}
      # 付费 qwen
      - QWEN_API_KEY=${ALIYUN_DASHSCOPE_API_KEY}

volumes:
  data:
    driver: local
  s3_data:
    driver: local

networks:
  lobe-network:
    driver: bridge
